digraph {
	graph [size="70.35,70.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	137921156514160 [label="
 (1, 1, 128, 128)" fillcolor=darkolivegreen1]
	137921196769232 [label=SigmoidBackward0]
	137921196764720 -> 137921196769232
	137921196764720 [label=ConvolutionBackward0]
	137921196768368 -> 137921196764720
	137921196768368 [label=ReluBackward0]
	137921196762848 -> 137921196768368
	137921196762848 [label=NativeBatchNormBackward0]
	137921196760064 -> 137921196762848
	137921196760064 [label=ConvolutionBackward0]
	137921196767888 -> 137921196760064
	137921196767888 [label=ReluBackward0]
	137921196759536 -> 137921196767888
	137921196759536 [label=NativeBatchNormBackward0]
	137921196760688 -> 137921196759536
	137921196760688 [label=ConvolutionBackward0]
	137921196761888 -> 137921196760688
	137921196761888 [label=CatBackward0]
	137921196767648 -> 137921196761888
	137921196767648 [label=ConvolutionBackward0]
	137921196767216 -> 137921196767648
	137921196767216 [label=ReluBackward0]
	137921196768464 -> 137921196767216
	137921196768464 [label=NativeBatchNormBackward0]
	137921196760112 -> 137921196768464
	137921196760112 [label=ConvolutionBackward0]
	137921196765008 -> 137921196760112
	137921196765008 [label=ReluBackward0]
	137921196760544 -> 137921196765008
	137921196760544 [label=NativeBatchNormBackward0]
	137921196766160 -> 137921196760544
	137921196766160 [label=ConvolutionBackward0]
	137921196768560 -> 137921196766160
	137921196768560 [label=CatBackward0]
	137921196764096 -> 137921196768560
	137921196764096 [label=ConvolutionBackward0]
	137921295370800 -> 137921196764096
	137921295370800 [label=ReluBackward0]
	137921295370176 -> 137921295370800
	137921295370176 [label=NativeBatchNormBackward0]
	137921295369552 -> 137921295370176
	137921295369552 [label=ConvolutionBackward0]
	137921295379344 -> 137921295369552
	137921295379344 [label=ReluBackward0]
	137921295377232 -> 137921295379344
	137921295377232 [label=NativeBatchNormBackward0]
	137921295370560 -> 137921295377232
	137921295370560 [label=ConvolutionBackward0]
	137921295370848 -> 137921295370560
	137921295370848 [label=CatBackward0]
	137921295381216 -> 137921295370848
	137921295381216 [label=ConvolutionBackward0]
	137921295373200 -> 137921295381216
	137921295373200 [label=ReluBackward0]
	137921295369504 -> 137921295373200
	137921295369504 [label=NativeBatchNormBackward0]
	137921295368496 -> 137921295369504
	137921295368496 [label=ConvolutionBackward0]
	137921295380400 -> 137921295368496
	137921295380400 [label=ReluBackward0]
	137921295371808 -> 137921295380400
	137921295371808 [label=NativeBatchNormBackward0]
	137921295383424 -> 137921295371808
	137921295383424 [label=ConvolutionBackward0]
	137921295375600 -> 137921295383424
	137921295375600 [label=CatBackward0]
	137921295373728 -> 137921295375600
	137921295373728 [label=ConvolutionBackward0]
	137921295378624 -> 137921295373728
	137921295378624 [label=ReluBackward0]
	137921295376848 -> 137921295378624
	137921295376848 [label=NativeBatchNormBackward0]
	137921295368304 -> 137921295376848
	137921295368304 [label=ConvolutionBackward0]
	137921295379824 -> 137921295368304
	137921295379824 [label=ReluBackward0]
	137921295376608 -> 137921295379824
	137921295376608 [label=NativeBatchNormBackward0]
	137921295375648 -> 137921295376608
	137921295375648 [label=ConvolutionBackward0]
	137921295370656 -> 137921295375648
	137921295370656 [label=MaxPool2DWithIndicesBackward0]
	137921295376800 -> 137921295370656
	137921295376800 [label=ReluBackward0]
	137921295380304 -> 137921295376800
	137921295380304 [label=NativeBatchNormBackward0]
	137921295382800 -> 137921295380304
	137921295382800 [label=ConvolutionBackward0]
	137921295381504 -> 137921295382800
	137921295381504 [label=ReluBackward0]
	137921295377376 -> 137921295381504
	137921295377376 [label=NativeBatchNormBackward0]
	137921295507488 -> 137921295377376
	137921295507488 [label=ConvolutionBackward0]
	137921295513872 -> 137921295507488
	137921295513872 [label=MaxPool2DWithIndicesBackward0]
	137921295381984 -> 137921295513872
	137921295381984 [label=ReluBackward0]
	137921295509360 -> 137921295381984
	137921295509360 [label=NativeBatchNormBackward0]
	137921295510800 -> 137921295509360
	137921295510800 [label=ConvolutionBackward0]
	137921295507536 -> 137921295510800
	137921295507536 [label=ReluBackward0]
	137921295500480 -> 137921295507536
	137921295500480 [label=NativeBatchNormBackward0]
	137921295511088 -> 137921295500480
	137921295511088 [label=ConvolutionBackward0]
	137921295501440 -> 137921295511088
	137921295501440 [label=MaxPool2DWithIndicesBackward0]
	137921196763472 -> 137921295501440
	137921196763472 [label=ReluBackward0]
	137921295514928 -> 137921196763472
	137921295514928 [label=NativeBatchNormBackward0]
	137921295505712 -> 137921295514928
	137921295505712 [label=ConvolutionBackward0]
	137921295500576 -> 137921295505712
	137921295500576 [label=ReluBackward0]
	137921295499904 -> 137921295500576
	137921295499904 [label=NativeBatchNormBackward0]
	137921295515216 -> 137921295499904
	137921295515216 [label=ConvolutionBackward0]
	137921295499664 -> 137921295515216
	137921295499664 [label=MaxPool2DWithIndicesBackward0]
	137921196769184 -> 137921295499664
	137921196769184 [label=ReluBackward0]
	137921295511424 -> 137921196769184
	137921295511424 [label=NativeBatchNormBackward0]
	137921295509792 -> 137921295511424
	137921295509792 [label=ConvolutionBackward0]
	137921295502160 -> 137921295509792
	137921295502160 [label=ReluBackward0]
	137921295504752 -> 137921295502160
	137921295504752 [label=NativeBatchNormBackward0]
	137921295507392 -> 137921295504752
	137921295507392 [label=ConvolutionBackward0]
	137921295500240 -> 137921295507392
	137921175798416 [label="encoder1.double_conv.0.weight
 (32, 12, 3, 3)" fillcolor=lightblue]
	137921175798416 -> 137921295500240
	137921295500240 [label=AccumulateGrad]
	137921295501488 -> 137921295507392
	137921175809264 [label="encoder1.double_conv.0.bias
 (32)" fillcolor=lightblue]
	137921175809264 -> 137921295501488
	137921295501488 [label=AccumulateGrad]
	137921295505088 -> 137921295504752
	137921175812912 [label="encoder1.double_conv.1.weight
 (32)" fillcolor=lightblue]
	137921175812912 -> 137921295505088
	137921295505088 [label=AccumulateGrad]
	137921295509744 -> 137921295504752
	137921175801584 [label="encoder1.double_conv.1.bias
 (32)" fillcolor=lightblue]
	137921175801584 -> 137921295509744
	137921295509744 [label=AccumulateGrad]
	137921295499424 -> 137921295509792
	137921176276336 [label="encoder1.double_conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	137921176276336 -> 137921295499424
	137921295499424 [label=AccumulateGrad]
	137921295501296 -> 137921295509792
	137921176276240 [label="encoder1.double_conv.3.bias
 (32)" fillcolor=lightblue]
	137921176276240 -> 137921295501296
	137921295501296 [label=AccumulateGrad]
	137921295514016 -> 137921295511424
	137921176275664 [label="encoder1.double_conv.4.weight
 (32)" fillcolor=lightblue]
	137921176275664 -> 137921295514016
	137921295514016 [label=AccumulateGrad]
	137921295508496 -> 137921295511424
	137921176276528 [label="encoder1.double_conv.4.bias
 (32)" fillcolor=lightblue]
	137921176276528 -> 137921295508496
	137921295508496 [label=AccumulateGrad]
	137921295507104 -> 137921295515216
	137921176277296 [label="encoder2.double_conv.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	137921176277296 -> 137921295507104
	137921295507104 [label=AccumulateGrad]
	137921295515168 -> 137921295515216
	137921176277200 [label="encoder2.double_conv.0.bias
 (64)" fillcolor=lightblue]
	137921176277200 -> 137921295515168
	137921295515168 [label=AccumulateGrad]
	137921295509216 -> 137921295499904
	137921176276912 [label="encoder2.double_conv.1.weight
 (64)" fillcolor=lightblue]
	137921176276912 -> 137921295509216
	137921295509216 [label=AccumulateGrad]
	137921295514544 -> 137921295499904
	137921176277104 [label="encoder2.double_conv.1.bias
 (64)" fillcolor=lightblue]
	137921176277104 -> 137921295514544
	137921295514544 [label=AccumulateGrad]
	137921295513536 -> 137921295505712
	137921176277776 [label="encoder2.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	137921176277776 -> 137921295513536
	137921295513536 [label=AccumulateGrad]
	137921295506672 -> 137921295505712
	137921176277680 [label="encoder2.double_conv.3.bias
 (64)" fillcolor=lightblue]
	137921176277680 -> 137921295506672
	137921295506672 [label=AccumulateGrad]
	137921295501536 -> 137921295514928
	137921176277584 [label="encoder2.double_conv.4.weight
 (64)" fillcolor=lightblue]
	137921176277584 -> 137921295501536
	137921295501536 [label=AccumulateGrad]
	137921295504944 -> 137921295514928
	137921176277872 [label="encoder2.double_conv.4.bias
 (64)" fillcolor=lightblue]
	137921176277872 -> 137921295504944
	137921295504944 [label=AccumulateGrad]
	137921295514112 -> 137921295511088
	137921176278352 [label="encoder3.double_conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	137921176278352 -> 137921295514112
	137921295514112 [label=AccumulateGrad]
	137921295506864 -> 137921295511088
	137921176278448 [label="encoder3.double_conv.0.bias
 (128)" fillcolor=lightblue]
	137921176278448 -> 137921295506864
	137921295506864 [label=AccumulateGrad]
	137921295510224 -> 137921295500480
	137921176278544 [label="encoder3.double_conv.1.weight
 (128)" fillcolor=lightblue]
	137921176278544 -> 137921295510224
	137921295510224 [label=AccumulateGrad]
	137921295508832 -> 137921295500480
	137921176278736 [label="encoder3.double_conv.1.bias
 (128)" fillcolor=lightblue]
	137921176278736 -> 137921295508832
	137921295508832 [label=AccumulateGrad]
	137921295501920 -> 137921295510800
	137921176279120 [label="encoder3.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	137921176279120 -> 137921295501920
	137921295501920 [label=AccumulateGrad]
	137921295502976 -> 137921295510800
	137921176279216 [label="encoder3.double_conv.3.bias
 (128)" fillcolor=lightblue]
	137921176279216 -> 137921295502976
	137921295502976 [label=AccumulateGrad]
	137921295505952 -> 137921295509360
	137921176279312 [label="encoder3.double_conv.4.weight
 (128)" fillcolor=lightblue]
	137921176279312 -> 137921295505952
	137921295505952 [label=AccumulateGrad]
	137921295510608 -> 137921295509360
	137921176279600 [label="encoder3.double_conv.4.bias
 (128)" fillcolor=lightblue]
	137921176279600 -> 137921295510608
	137921295510608 [label=AccumulateGrad]
	137921295507152 -> 137921295507488
	137921176278928 [label="encoder4.double_conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	137921176278928 -> 137921295507152
	137921295507152 [label=AccumulateGrad]
	137921295500864 -> 137921295507488
	137921176278832 [label="encoder4.double_conv.0.bias
 (256)" fillcolor=lightblue]
	137921176278832 -> 137921295500864
	137921295500864 [label=AccumulateGrad]
	137921295507056 -> 137921295377376
	137921176279696 [label="encoder4.double_conv.1.weight
 (256)" fillcolor=lightblue]
	137921176279696 -> 137921295507056
	137921295507056 [label=AccumulateGrad]
	137921295510464 -> 137921295377376
	137921176279888 [label="encoder4.double_conv.1.bias
 (256)" fillcolor=lightblue]
	137921176279888 -> 137921295510464
	137921295510464 [label=AccumulateGrad]
	137921295378768 -> 137921295382800
	137921176280272 [label="encoder4.double_conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	137921176280272 -> 137921295378768
	137921295378768 [label=AccumulateGrad]
	137921295380064 -> 137921295382800
	137921176280464 [label="encoder4.double_conv.3.bias
 (256)" fillcolor=lightblue]
	137921176280464 -> 137921295380064
	137921295380064 [label=AccumulateGrad]
	137921295378528 -> 137921295380304
	137921176280080 [label="encoder4.double_conv.4.weight
 (256)" fillcolor=lightblue]
	137921176280080 -> 137921295378528
	137921295378528 [label=AccumulateGrad]
	137921295372720 -> 137921295380304
	137921176280656 [label="encoder4.double_conv.4.bias
 (256)" fillcolor=lightblue]
	137921176280656 -> 137921295372720
	137921295372720 [label=AccumulateGrad]
	137921295368544 -> 137921295375648
	137921176281040 [label="bottleneck.double_conv.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	137921176281040 -> 137921295368544
	137921295368544 [label=AccumulateGrad]
	137921295383280 -> 137921295375648
	137921176281232 [label="bottleneck.double_conv.0.bias
 (512)" fillcolor=lightblue]
	137921176281232 -> 137921295383280
	137921295383280 [label=AccumulateGrad]
	137921295369312 -> 137921295376608
	137921176280560 [label="bottleneck.double_conv.1.weight
 (512)" fillcolor=lightblue]
	137921176280560 -> 137921295369312
	137921295369312 [label=AccumulateGrad]
	137921295382368 -> 137921295376608
	137921176280944 [label="bottleneck.double_conv.1.bias
 (512)" fillcolor=lightblue]
	137921176280944 -> 137921295382368
	137921295382368 [label=AccumulateGrad]
	137921295380496 -> 137921295368304
	137921176281328 [label="bottleneck.double_conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	137921176281328 -> 137921295380496
	137921295380496 [label=AccumulateGrad]
	137921295381360 -> 137921295368304
	137921176281712 [label="bottleneck.double_conv.3.bias
 (512)" fillcolor=lightblue]
	137921176281712 -> 137921295381360
	137921295381360 [label=AccumulateGrad]
	137921295377424 -> 137921295376848
	137921176281520 [label="bottleneck.double_conv.4.weight
 (512)" fillcolor=lightblue]
	137921176281520 -> 137921295377424
	137921295377424 [label=AccumulateGrad]
	137921295377136 -> 137921295376848
	137921176282000 [label="bottleneck.double_conv.4.bias
 (512)" fillcolor=lightblue]
	137921176282000 -> 137921295377136
	137921295377136 [label=AccumulateGrad]
	137921295380880 -> 137921295373728
	137921176282384 [label="up4.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	137921176282384 -> 137921295380880
	137921295380880 [label=AccumulateGrad]
	137921295370752 -> 137921295373728
	137921176282576 [label="up4.bias
 (256)" fillcolor=lightblue]
	137921176282576 -> 137921295370752
	137921295370752 [label=AccumulateGrad]
	137921295376800 -> 137921295375600
	137921295382752 -> 137921295383424
	137921176282096 [label="decoder4.double_conv.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	137921176282096 -> 137921295382752
	137921295382752 [label=AccumulateGrad]
	137921295377328 -> 137921295383424
	137921176282864 [label="decoder4.double_conv.0.bias
 (256)" fillcolor=lightblue]
	137921176282864 -> 137921295377328
	137921295377328 [label=AccumulateGrad]
	137921295377760 -> 137921295371808
	137921176282672 [label="decoder4.double_conv.1.weight
 (256)" fillcolor=lightblue]
	137921176282672 -> 137921295377760
	137921295377760 [label=AccumulateGrad]
	137921295379440 -> 137921295371808
	137921176282480 [label="decoder4.double_conv.1.bias
 (256)" fillcolor=lightblue]
	137921176282480 -> 137921295379440
	137921295379440 [label=AccumulateGrad]
	137921295384528 -> 137921295368496
	137921176283248 [label="decoder4.double_conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	137921176283248 -> 137921295384528
	137921295384528 [label=AccumulateGrad]
	137921295379584 -> 137921295368496
	137921176283536 [label="decoder4.double_conv.3.bias
 (256)" fillcolor=lightblue]
	137921176283536 -> 137921295379584
	137921295379584 [label=AccumulateGrad]
	137921295374880 -> 137921295369504
	137921176283440 [label="decoder4.double_conv.4.weight
 (256)" fillcolor=lightblue]
	137921176283440 -> 137921295374880
	137921295374880 [label=AccumulateGrad]
	137921295377280 -> 137921295369504
	137921176282768 [label="decoder4.double_conv.4.bias
 (256)" fillcolor=lightblue]
	137921176282768 -> 137921295377280
	137921295377280 [label=AccumulateGrad]
	137921295377664 -> 137921295381216
	137921176283824 [label="up3.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	137921176283824 -> 137921295377664
	137921295377664 [label=AccumulateGrad]
	137921295373056 -> 137921295381216
	137921176284208 [label="up3.bias
 (128)" fillcolor=lightblue]
	137921176284208 -> 137921295373056
	137921295373056 [label=AccumulateGrad]
	137921295381984 -> 137921295370848
	137921295379968 -> 137921295370560
	137921176284112 [label="decoder3.double_conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	137921176284112 -> 137921295379968
	137921295379968 [label=AccumulateGrad]
	137921295381648 -> 137921295370560
	137921176284496 [label="decoder3.double_conv.0.bias
 (128)" fillcolor=lightblue]
	137921176284496 -> 137921295381648
	137921295381648 [label=AccumulateGrad]
	137921295372048 -> 137921295377232
	137921176284400 [label="decoder3.double_conv.1.weight
 (128)" fillcolor=lightblue]
	137921176284400 -> 137921295372048
	137921295372048 [label=AccumulateGrad]
	137921295381456 -> 137921295377232
	137921176284304 [label="decoder3.double_conv.1.bias
 (128)" fillcolor=lightblue]
	137921176284304 -> 137921295381456
	137921295381456 [label=AccumulateGrad]
	137921295377184 -> 137921295369552
	137921176285072 [label="decoder3.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	137921176285072 -> 137921295377184
	137921295377184 [label=AccumulateGrad]
	137921295378432 -> 137921295369552
	137921176285168 [label="decoder3.double_conv.3.bias
 (128)" fillcolor=lightblue]
	137921176285168 -> 137921295378432
	137921295378432 [label=AccumulateGrad]
	137921295378864 -> 137921295370176
	137921176285264 [label="decoder3.double_conv.4.weight
 (128)" fillcolor=lightblue]
	137921176285264 -> 137921295378864
	137921295378864 [label=AccumulateGrad]
	137921295370608 -> 137921295370176
	137921176285552 [label="decoder3.double_conv.4.bias
 (128)" fillcolor=lightblue]
	137921176285552 -> 137921295370608
	137921295370608 [label=AccumulateGrad]
	137921295380736 -> 137921196764096
	137921176285744 [label="up2.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	137921176285744 -> 137921295380736
	137921295380736 [label=AccumulateGrad]
	137921295381024 -> 137921196764096
	137921176285840 [label="up2.bias
 (64)" fillcolor=lightblue]
	137921176285840 -> 137921295381024
	137921295381024 [label=AccumulateGrad]
	137921196763472 -> 137921196768560
	137921196759776 -> 137921196766160
	137921176285936 [label="decoder2.double_conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	137921176285936 -> 137921196759776
	137921196759776 [label=AccumulateGrad]
	137921196768416 -> 137921196766160
	137921176286032 [label="decoder2.double_conv.0.bias
 (64)" fillcolor=lightblue]
	137921176286032 -> 137921196768416
	137921196768416 [label=AccumulateGrad]
	137921196761360 -> 137921196760544
	137921176286416 [label="decoder2.double_conv.1.weight
 (64)" fillcolor=lightblue]
	137921176286416 -> 137921196761360
	137921196761360 [label=AccumulateGrad]
	137921196764336 -> 137921196760544
	137921176286224 [label="decoder2.double_conv.1.bias
 (64)" fillcolor=lightblue]
	137921176286224 -> 137921196764336
	137921196764336 [label=AccumulateGrad]
	137921196769040 -> 137921196760112
	137921175847184 [label="decoder2.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	137921175847184 -> 137921196769040
	137921196769040 [label=AccumulateGrad]
	137921196769136 -> 137921196760112
	137921175847088 [label="decoder2.double_conv.3.bias
 (64)" fillcolor=lightblue]
	137921175847088 -> 137921196769136
	137921196769136 [label=AccumulateGrad]
	137921196760880 -> 137921196768464
	137921175847472 [label="decoder2.double_conv.4.weight
 (64)" fillcolor=lightblue]
	137921175847472 -> 137921196760880
	137921196760880 [label=AccumulateGrad]
	137921196764192 -> 137921196768464
	137921175847280 [label="decoder2.double_conv.4.bias
 (64)" fillcolor=lightblue]
	137921175847280 -> 137921196764192
	137921196764192 [label=AccumulateGrad]
	137921196767600 -> 137921196767648
	137921176204976 [label="up1.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	137921176204976 -> 137921196767600
	137921196767600 [label=AccumulateGrad]
	137921196763088 -> 137921196767648
	137921176192592 [label="up1.bias
 (32)" fillcolor=lightblue]
	137921176192592 -> 137921196763088
	137921196763088 [label=AccumulateGrad]
	137921196769184 -> 137921196761888
	137921196767312 -> 137921196760688
	137921176205552 [label="decoder1.double_conv.0.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	137921176205552 -> 137921196767312
	137921196767312 [label=AccumulateGrad]
	137921196759632 -> 137921196760688
	137921176207088 [label="decoder1.double_conv.0.bias
 (32)" fillcolor=lightblue]
	137921176207088 -> 137921196759632
	137921196759632 [label=AccumulateGrad]
	137921196767072 -> 137921196759536
	137921176205360 [label="decoder1.double_conv.1.weight
 (32)" fillcolor=lightblue]
	137921176205360 -> 137921196767072
	137921196767072 [label=AccumulateGrad]
	137921196766448 -> 137921196759536
	137921176199120 [label="decoder1.double_conv.1.bias
 (32)" fillcolor=lightblue]
	137921176199120 -> 137921196766448
	137921196766448 [label=AccumulateGrad]
	137921196761840 -> 137921196760064
	137921176195280 [label="decoder1.double_conv.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	137921176195280 -> 137921196761840
	137921196761840 [label=AccumulateGrad]
	137921196767408 -> 137921196760064
	137921176204784 [label="decoder1.double_conv.3.bias
 (32)" fillcolor=lightblue]
	137921176204784 -> 137921196767408
	137921196767408 [label=AccumulateGrad]
	137921196761792 -> 137921196762848
	137921176193168 [label="decoder1.double_conv.4.weight
 (32)" fillcolor=lightblue]
	137921176193168 -> 137921196761792
	137921196761792 [label=AccumulateGrad]
	137921196767168 -> 137921196762848
	137921176205168 [label="decoder1.double_conv.4.bias
 (32)" fillcolor=lightblue]
	137921176205168 -> 137921196767168
	137921196767168 [label=AccumulateGrad]
	137921196767360 -> 137921196764720
	137921176201136 [label="out.weight
 (1, 32, 1, 1)" fillcolor=lightblue]
	137921176201136 -> 137921196767360
	137921196767360 [label=AccumulateGrad]
	137921196764384 -> 137921196764720
	137921176192016 [label="out.bias
 (1)" fillcolor=lightblue]
	137921176192016 -> 137921196764384
	137921196764384 [label=AccumulateGrad]
	137921196769232 -> 137921156514160
}
